import tweepy
from tweepy import OAuthHandler
import pandas as pd


print("Begin scraping.")

access_token = ''
access_token_secret = ''
consumer_key = ''
consumer_secret = ''

auth = tweepy.OAuthHandler(consumer_key, consumer_secret)
auth.set_access_token(access_token, access_token_secret)

api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)

tweets = []

count = 1

#Twitter only pulls a sample of tweets from the last 7 days. 
#Enter one or multiple comma seperated items in search terms = '', can be hashtags, keywords, handles, or key phrases of interest. 
#Manually add in the number of tweets you want to get back in items(). 
#Searches can further be filtered by added "-filter: retweets" or lang='en'.

search_term = ''

for tweet in tweepy.Cursor(api.search, 
                           q= search_term, 
                           count=5000, 
                           tweet_mode='extended',
                           result_type='top',
                           since='YYYY-MM-DD').items():
    
    count += 1

    #check if the user specify location of his/her tweet
    #we default this to 0
    place_full_name=0
    exact_coordinates=0
    box_coordinates=0
    if type(tweet.place) == tweepy.models.Place:
        try:
            #check if the location is specific
            #if exist this data is in a [long,lat] list instead of [lat,long]
            # e.g. [35.0, 135.0]
            exact_coordinates=tweet.place.coordinates
        except AttributeError as e:
            #coordinatnates is a bounding
            #this data is a list of coordinates in [lat,long] list
            # e.g. [[135.0, 35.0],[135.0, 35.1],[135.1, 35.0],[135.1, 35.1]]
            box_coodinates=tweet.place.bounding_box.coordinates
            place_full_name=tweet.place.full_name

    try: 
        data = [
            tweet.created_at, 
            tweet.id_str, 
            tweet.full_text, 
            tweet.favorite_count, 
            tweet.retweet_count, 
            tweet.lang,
            tweet.user._json['screen_name'], 
            tweet.user._json['name'], 
            exact_coordinates,
	    box_coordinates,
	    place_full_name,
            tweet.user.location, 
            tweet.user.followers_count,
            tweet.user.friends_count,
            tweet.user.description,
            tweet.user.listed_count,
            tweet.user.statuses_count,
            tweet.source,
            tweet.in_reply_to_status_id_str, 
            tweet.in_reply_to_user_id_str, 
            tweet.is_quote_status,
            tweet.user._json['created_at'], 
            tweet.entities['urls']
        ]
        data = tuple(data)
        tweets.append(data)

    except tweepy.TweepError as e:
        print(e.reason)
        continue

    except StopIteration:
        break

df = pd.DataFrame(tweets, columns = [
    'creation time',
    'tweet id', 
    'tweet text', 
    'favorite count', 
    'retweet count', 
    'tweet language',
    'screen name', 
    'name',
    'exact_coordinates',
    'bounding_coordinates',
    'place_full_name',
    'user reported location', 
    'followers',
    'following',
    'description',
    'listed_count',
    'total number of tweets by user',
    'source',
    'if reply original tweet id',
    'if reply original user id',
    'quote tweet',
    'account creation date', 
    'urls'
])

#Add the path to the folder as well as the name of the output CSV file inside the single quotations

df.to_csv(path_or_buf = '', encoding='utf-8', index=False) 

print("Finished scraping.")
